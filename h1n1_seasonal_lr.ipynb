{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "# to display output inside the notebook\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 0    # Set a random seed for reproducibility!\n",
    "\n",
    "pd.set_option('display.max_columns', 100) # to display maximum columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featues and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\n",
    "    'training_set_features.csv',\n",
    "    index_col=\"respondent_id\"\n",
    ")\n",
    "labels_df = pd.read_csv(\n",
    "    'training_set_labels.csv',\n",
    "    index_col=\"respondent_id\"\n",
    ")\n",
    "test_features_df = pd.read_csv(\n",
    "    'test_set_features.csv',\n",
    "    index_col=\"respondent_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features_df: (26707, 35)\n",
      "shape of labels_df: (26707, 2)\n",
      "shape of test_features_df: (26708, 35)\n"
     ]
    }
   ],
   "source": [
    "print('shape of features_df:' , features_df.shape)\n",
    "print('shape of labels_df:', labels_df.shape)\n",
    "print('shape of test_features_df:' , test_features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the two classes\n",
    "labels_df_h1n1 = labels_df[['h1n1_vaccine']]\n",
    "labels_df_seasonal = labels_df[['seasonal_vaccine']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment_occupation          50.436215\n",
       "employment_industry            49.912008\n",
       "health_insurance               45.957989\n",
       "income_poverty                 16.561201\n",
       "doctor_recc_h1n1                8.087767\n",
       "doctor_recc_seasonal            8.087767\n",
       "rent_or_own                     7.645936\n",
       "employment_status               5.477965\n",
       "marital_status                  5.272026\n",
       "education                       5.268282\n",
       "chronic_med_condition           3.635751\n",
       "child_under_6_months            3.070356\n",
       "health_worker                   3.010447\n",
       "opinion_seas_sick_from_vacc     2.010709\n",
       "opinion_seas_risk               1.924589\n",
       "opinion_seas_vacc_effective     1.729884\n",
       "opinion_h1n1_sick_from_vacc     1.479013\n",
       "opinion_h1n1_vacc_effective     1.464036\n",
       "opinion_h1n1_risk               1.452803\n",
       "household_children              0.932340\n",
       "household_adults                0.932340\n",
       "behavioral_avoidance            0.778822\n",
       "behavioral_touch_face           0.479275\n",
       "h1n1_knowledge                  0.434343\n",
       "h1n1_concern                    0.344479\n",
       "behavioral_large_gatherings     0.325757\n",
       "behavioral_outside_home         0.307036\n",
       "behavioral_antiviral_meds       0.265848\n",
       "behavioral_wash_hands           0.157262\n",
       "behavioral_face_mask            0.071142\n",
       "sex                             0.000000\n",
       "race                            0.000000\n",
       "hhs_geo_region                  0.000000\n",
       "census_msa                      0.000000\n",
       "age_group                       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of null values in features\n",
    "((features_df.isnull().sum()/len(features_df) * 100  )).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical columns: 23\n",
      "non numerical (categorical) columns: 12\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = features_df.columns[features_df.dtypes != 'object'].values\n",
    "non_numeric_cols = features_df.columns[features_df.dtypes == 'object'].values\n",
    "\n",
    "print('numerical columns:', len(numeric_cols))\n",
    "print('non numerical (categorical) columns:', len(non_numeric_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('simple_imputer', SimpleImputer(strategy = 'mean'))\n",
    "])\n",
    "\n",
    "non_numeric_preprocessing_steps = Pipeline([\n",
    "     ('simple_imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('one_hot_encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('numeric', numeric_preprocessing_steps, numeric_cols),\n",
    "        ('non_numeric', non_numeric_preprocessing_steps, non_numeric_cols)  \n",
    "    ],\n",
    "    remainder = \"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_preprocess = pd.DataFrame(preprocessor.transform(features_df))\n",
    "test_features_df_preprocess = pd.DataFrame(preprocessor.transform(test_features_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_h1n1 = LogisticRegression()\n",
    "model_seasonal = LogisticRegression()\n",
    "\n",
    "model_h1n1.fit(features_df_preprocess, labels_df_h1n1)\n",
    "model_seasonal.fit(features_df_preprocess, labels_df_seasonal)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1_h1n1 = model_h1n1.predict_proba(test_features_df_preprocess)\n",
    "preds2_seasonal = model_seasonal.predict_proba(test_features_df_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds1_h1n1.shape: (26708, 1)\n",
      "y_preds2_seasonal.shape: (26708, 1)\n"
     ]
    }
   ],
   "source": [
    "y_preds1_h1n1 = pd.DataFrame(\n",
    "    {\n",
    "        \"h1n1_vaccine\": preds1_h1n1[:, 1],\n",
    "        \n",
    "    },\n",
    "    index = test_features_df.index\n",
    ")\n",
    "\n",
    "y_preds2_seasonal = pd.DataFrame(\n",
    "    {\n",
    "        \"seasonal_vaccine\": preds2_seasonal[:, 1],\n",
    "        \n",
    "    },\n",
    "    index = test_features_df.index\n",
    ")\n",
    "print(\"y_preds1_h1n1.shape:\", y_preds1_h1n1.shape)\n",
    "print(\"y_preds2_seasonal.shape:\", y_preds2_seasonal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds1_h1n1.to_csv('h1n1_submision.csv', index=True)\n",
    "y_preds2_seasonal.to_csv('seasonal_submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = y_preds1_h1n1.join(y_preds2_seasonal)\n",
    "joined_df.head()\n",
    "\n",
    "joined_df.to_csv('final_submission.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
